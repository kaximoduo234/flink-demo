# Apache Flink + Paimon Demo

[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Flink](https://img.shields.io/badge/Apache%20Flink-1.20.1-E6526F?style=for-the-badge&logo=apache-flink&logoColor=white)](https://flink.apache.org/)
[![Apache Paimon](https://img.shields.io/badge/Apache%20Paimon-1.0.0-blue?style=for-the-badge)](https://paimon.apache.org/)
[![Java](https://img.shields.io/badge/Java-17-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)](https://openjdk.org/projects/jdk/17/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

> ğŸ‰ **æœ€æ–°æ›´æ–°**: å·²å‡çº§è‡³ **Flink 1.20.1** + **Java 17** + **Paimon 1.0.0**ï¼Œäº«å—æœ€æ–°ç‰¹æ€§å’Œæ€§èƒ½æå‡ï¼

ğŸŒ **[ä¸­æ–‡æ–‡æ¡£](#ä¸­æ–‡æ–‡æ¡£) | [English Documentation](#english-documentation)**

---

<a name="english-documentation"></a>
## ğŸ‡ºğŸ‡¸ English Documentation

A comprehensive Apache Flink streaming platform demo with pre-integrated Apache Paimon connector, containerized using Docker Compose for production-ready deployment.

### ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Services Overview](#-services-overview)
- [Configuration](#-configuration)
- [Development](#-development)
- [Usage Examples](#-usage-examples)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

### âœ¨ Features

- ğŸš€ **One-Click Deployment** - Automated build and startup with Docker Compose
- ğŸ“¦ **Latest Stack** - Flink 1.20.1 + Java 17 + Paimon 1.0.0 for optimal performance
- ğŸ—ï¸ **Complete Data Stack** - Flink + Kafka + MySQL + Doris + Redis
- ğŸ”§ **Production Ready** - Containerized deployment with proper configurations
- ğŸ› ï¸ **Developer Friendly** - Easy to extend with custom JARs and configurations
- ğŸ“Š **Multiple Data Sources** - Support for various input/output connectors
- ğŸ”„ **Stream Processing** - Real-time data processing capabilities
- ğŸ“ˆ **Monitoring Ready** - Built-in web UIs for all components
- âš¡ **Modern APIs** - Uses latest Flink Configuration API and Jackson JSON processing
- ğŸ”’ **Enhanced Security** - Removed deprecated FastJSON, improved dependency management

### ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           Flink Cluster                 â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
                    â”‚  â”‚JobManager   â”‚â”€â”€â”€â”‚TaskManager  â”‚     â”‚
                    â”‚  â”‚(Master)     â”‚   â”‚(Worker)     â”‚     â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Apache    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Apache    â”‚
    â”‚   Kafka     â”‚              â”‚              â”‚   Doris     â”‚
    â”‚ (Streaming) â”‚              â”‚              â”‚(Analytics)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   MySQL     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Redis     â”‚
    â”‚(Transactional)              â”‚              â”‚  (Cache)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Apache Paimon â”‚
                          â”‚   (Lake Store) â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ Prerequisites

- **Docker** (version 20.10+) - [Installation Guide](https://docs.docker.com/get-docker/)
- **Docker Compose** (version 2.0+) - [Installation Guide](https://docs.docker.com/compose/install/)
- **Git** - [Installation Guide](https://git-scm.com/downloads)
- **Java 17** (for development) - [Installation Guide](https://openjdk.org/projects/jdk/17/)
- **Maven 3.6+** (for building) - [Installation Guide](https://maven.apache.org/install.html)
- At least **8GB RAM** and **10GB** free disk space

### ğŸ†• What's New in v1.1.0

#### ğŸ¯ Major Upgrades
- **Apache Flink**: 1.17.1 â†’ **1.20.1** (Latest stable release)
- **Java Runtime**: 11 â†’ **17** (Enhanced performance and security)
- **Apache Paimon**: 0.8.2 â†’ **1.0.0** (Production-ready features, å®é™…ä½¿ç”¨ç‰ˆæœ¬)

#### ğŸ”§ Technical Improvements
- **Modern Configuration API**: Uses new `Configuration` + `ConfigOptions` pattern
- **Enhanced Security**: Replaced FastJSON with Jackson ObjectMapper
- **Better Dependency Management**: Resolved version conflicts and added missing dependencies
- **Docker Optimization**: Fixed network conflicts and updated base images
- **Code Modernization**: Removed all deprecated APIs and warnings

#### ğŸš€ Performance Enhancements
- **Java 17 Benefits**: Improved GC performance and memory efficiency  
- **Flink 1.20.1 Features**: Better checkpoint mechanisms and state management
- **Connector Updates**: Latest Kafka, JDBC, and CDC connectors for better stability

> ğŸ“– **Migration Guide**: See [CHANGELOG.md](CHANGELOG.md) for detailed upgrade instructions

### ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/flink-demo.git
cd flink-demo

# Start all services (one-click deployment)
docker-compose up --build -d

# Verify services
docker-compose ps
```

### ğŸŒ Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Flink Dashboard** | http://localhost:8081 | - |
| **MySQL (Adminer)** | http://localhost:8080 | root/root123 |
| **Doris FE** | http://localhost:8030 | root/(empty) |
| **StreamPark** | http://localhost:10000 | admin/streampark |

### ğŸ› ï¸ Services Overview

| Service | Version | Port(s) | Description |
|---------|---------|---------|-------------|
| **Apache Flink** | 1.20.1 | 8081 | Stream processing engine with Paimon |
| **Apache Kafka** | Latest | 9092 | Distributed streaming platform |
| **MySQL** | 8.0 | 3306 | Relational database with CDC enabled |
| **Apache Doris** | Latest | 8030, 9030 | MPP analytical database |
| **Redis** | 6.2 | 6379 | In-memory data structure store |
| **StreamPark** | 2.1.5 | 10000 | Flink job management platform |

### ğŸ“– Usage Examples

#### ğŸš€ Complete Paimon Quick Start Tutorial

This tutorial provides a step-by-step guide to test Paimon functionality with real-time data.

**Step 1: Access Flink SQL Client**
```bash
# Enter Flink JobManager container
docker exec -it jobmanager bash

# Start Flink SQL Client
./bin/sql-client.sh
```

**Step 2: Basic Paimon Setup (Copy & Run)**
```sql
-- Create Paimon catalog
CREATE CATALOG my_catalog WITH (
  'type' = 'paimon',
  'warehouse' = 'file:/warehouse'
);

-- Switch to Paimon catalog (IMPORTANT: Required for subsequent operations)
USE CATALOG my_catalog;

-- Create main table with primary key
-- Note: PRIMARY KEY NOT ENFORCED means supports deduplication but not mandatory
CREATE TABLE word_count (
  word STRING PRIMARY KEY NOT ENFORCED,
  cnt BIGINT
);

-- Create data source table using Flink's built-in datagen connector
CREATE TEMPORARY TABLE word_table (
  word STRING
) WITH (
  'connector' = 'datagen',
  'fields.word.length' = '1'  -- Generates single character words (a, b, c, etc.)
);

-- Enable checkpointing for fault tolerance
SET 'execution.checkpointing.interval' = '10 s';

-- Start streaming job: Insert real-time aggregated data
INSERT INTO word_count
SELECT word, COUNT(*) FROM word_table GROUP BY word;
```


**Step 3: Monitor Results in Real-time**

Open a **second terminal session** while the INSERT job is running:
```bash
# Open another SQL Client session
docker exec -it jobmanager ./bin/sql-client.sh
```

```sql
USE CATALOG my_catalog;

-- Query real-time results (will show continuously growing counts)
SELECT * FROM word_count;

-- Expected output (counts will keep increasing):
/*
+----+--------------------------------+----------------------+
| op |                           word |                  cnt |
+----+--------------------------------+----------------------+
| +I |                              a |                   45 |
| +I |                              b |                   38 |
| +I |                              c |                   42 |
| +I |                              d |                   51 |
+----+--------------------------------+----------------------+
*/
```

**Step 4: Switch to Batch Mode (OLAP Query)**
```sql
-- Configure for batch processing (static snapshot)
SET 'sql-client.execution.result-mode' = 'tableau';
RESET 'execution.checkpointing.interval';
SET 'execution.runtime-mode' = 'batch';

-- Query static snapshot (won't auto-refresh)
SELECT * FROM word_count ORDER BY cnt DESC LIMIT 5;

-- This demonstrates Paimon's "storage-compute separation" design
-- Stream mode: Real-time updates | Batch mode: Static analysis
```

**Step 5: Advanced Example - Business Table**
```sql
-- Create a business orders table
CREATE TABLE orders (
  order_id BIGINT,
  user_id BIGINT,
  product_id BIGINT,
  order_time TIMESTAMP(3),
  amount DECIMAL(10,2),
  PRIMARY KEY (order_id) NOT ENFORCED
) WITH ('bucket' = '4');

-- Insert sample data
INSERT INTO orders VALUES
(1001, 101, 201, TIMESTAMP '2024-01-15 10:30:00', 99.99),
(1002, 102, 202, TIMESTAMP '2024-01-15 11:15:00', 149.50),
(1003, 101, 203, TIMESTAMP '2024-01-15 12:00:00', 79.99);

-- Query data
SELECT * FROM orders;
```

**Step 6: Cleanup & Exit**
```sql
-- Optional cleanup
DROP TABLE word_count;
DROP TABLE orders;

-- Exit SQL Client
QUIT;
```

#### ğŸ“Š Expected Results & Verification

1. **Flink Web UI Status**: Visit http://localhost:8081 to see running jobs
2. **Real-time Growth**: `word_count` query results should show increasing numbers
3. **Batch vs Stream**: Notice the difference in query behavior between modes

#### ğŸ” Troubleshooting Tips

- **Catalog Error**: Always use `USE CATALOG my_catalog` after creating the catalog
- **No Data**: Check if the INSERT job is running in Flink Web UI
- **Permission Issues**: Ensure `/warehouse` directory is writable in containers

#### ğŸ“„ Ready-to-Use Script

For convenience, you can also use the complete test script:
```bash
# Copy the ready-to-use SQL script
cat examples/paimon-quick-test.sql

# Or execute it directly in SQL Client
# æˆ–åœ¨ SQL å®¢æˆ·ç«¯ä¸­ç›´æ¥æ‰§è¡Œ
```
The script contains all the commands above with detailed comments in both English and Chinese.

### ğŸ”§ Development

#### Adding Custom JARs
1. Place JAR files in `flink-jars/` directory
2. Rebuild: `docker-compose up --build -d jobmanager taskmanager`

#### Custom Configuration
- Flink: Edit `FLINK_PROPERTIES` in `docker-compose.yml`
- MySQL: Place scripts in `sql-scripts/` directory
- Doris: Modify `doris/*/conf/` configuration files

### ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

### ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

<a name="ä¸­æ–‡æ–‡æ¡£"></a>
## ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ–‡æ¡£

ä¸€ä¸ªé›†æˆäº† Apache Paimon è¿æ¥å™¨çš„ç»¼åˆæ€§ Apache Flink æµå¤„ç†å¹³å°æ¼”ç¤ºé¡¹ç›®ï¼Œä½¿ç”¨ Docker Compose è¿›è¡Œå®¹å™¨åŒ–éƒ¨ç½²ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

### ğŸ“‹ ç›®å½•

- [åŠŸèƒ½ç‰¹æ€§](#-åŠŸèƒ½ç‰¹æ€§)
- [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„)
- [ç¯å¢ƒè¦æ±‚](#-ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [æœåŠ¡æ¦‚è§ˆ](#-æœåŠ¡æ¦‚è§ˆ)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [å¼€å‘æŒ‡å—](#-å¼€å‘æŒ‡å—)
- [ä½¿ç”¨ç¤ºä¾‹](#-ä½¿ç”¨ç¤ºä¾‹)
- [æ•…éšœæ’æŸ¥](#-æ•…éšœæ’æŸ¥)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)
- [è®¸å¯è¯](#-è®¸å¯è¯)

### âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **ä¸€é”®éƒ¨ç½²** - é€šè¿‡ Docker Compose è‡ªåŠ¨æ„å»ºå’Œå¯åŠ¨
- ğŸ“¦ **æœ€æ–°æŠ€æœ¯æ ˆ** - Flink 1.20.1 + Java 17 + Paimon 1.0.0 æœ€ä½³æ€§èƒ½
- ğŸ—ï¸ **å®Œæ•´æ•°æ®æ ˆ** - Flink + Kafka + MySQL + Doris + Redis
- ğŸ”§ **ç”Ÿäº§å°±ç»ª** - å®¹å™¨åŒ–éƒ¨ç½²ï¼Œé…ç½®åˆç†
- ğŸ› ï¸ **å¼€å‘å‹å¥½** - æ˜“äºæ‰©å±•è‡ªå®šä¹‰ JAR å’Œé…ç½®
- ğŸ“Š **å¤šç§æ•°æ®æº** - æ”¯æŒå„ç§è¾“å…¥è¾“å‡ºè¿æ¥å™¨
- ğŸ”„ **æµå¼å¤„ç†** - å®æ—¶æ•°æ®å¤„ç†èƒ½åŠ›
- ğŸ“ˆ **ç›‘æ§å°±ç»ª** - å†…ç½®æ‰€æœ‰ç»„ä»¶çš„ Web UI
- âš¡ **ç°ä»£åŒ– API** - ä½¿ç”¨æœ€æ–° Flink Configuration API å’Œ Jackson JSON å¤„ç†
- ğŸ”’ **å®‰å…¨å¢å¼º** - ç§»é™¤è¿‡æ—¶çš„ FastJSONï¼Œæ”¹è¿›ä¾èµ–ç®¡ç†

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           Flink é›†ç¾¤                    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
                    â”‚  â”‚JobManager   â”‚â”€â”€â”€â”‚TaskManager  â”‚     â”‚
                    â”‚  â”‚(ä¸»èŠ‚ç‚¹)     â”‚   â”‚(å·¥ä½œèŠ‚ç‚¹)   â”‚     â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Apache    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Apache    â”‚
    â”‚   Kafka     â”‚              â”‚              â”‚   Doris     â”‚
    â”‚  (æµå¤„ç†)   â”‚              â”‚              â”‚ (åˆ†æå‹DB)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   MySQL     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Redis     â”‚
    â”‚ (äº‹åŠ¡å‹DB)  â”‚              â”‚              â”‚  (ç¼“å­˜)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Apache Paimon â”‚
                          â”‚   (æ¹–ä»“å­˜å‚¨)   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

- **Docker** (ç‰ˆæœ¬ 20.10+) - [å®‰è£…æŒ‡å—](https://docs.docker.com/get-docker/)
- **Docker Compose** (ç‰ˆæœ¬ 2.0+) - [å®‰è£…æŒ‡å—](https://docs.docker.com/compose/install/)
- **Git** - [å®‰è£…æŒ‡å—](https://git-scm.com/downloads)
- **Java 17** (å¼€å‘ç¯å¢ƒ) - [å®‰è£…æŒ‡å—](https://openjdk.org/projects/jdk/17/)
- **Maven 3.6+** (æ„å»ºå·¥å…·) - [å®‰è£…æŒ‡å—](https://maven.apache.org/install.html)
- è‡³å°‘ **8GB å†…å­˜** å’Œ **10GB** å¯ç”¨ç£ç›˜ç©ºé—´

### ğŸ†• v1.1.0 ç‰ˆæœ¬æ–°ç‰¹æ€§

#### ğŸ¯ é‡å¤§å‡çº§
- **Apache Flink**: 1.17.1 â†’ **1.20.1** (æœ€æ–°ç¨³å®šç‰ˆ)
- **Java è¿è¡Œæ—¶**: 11 â†’ **17** (æ€§èƒ½å’Œå®‰å…¨æ€§æå‡)
- **Apache Paimon**: 0.8.2 â†’ **1.0.0** (ç”Ÿäº§å°±ç»ªç‰¹æ€§ï¼Œå®é™…ä½¿ç”¨ç‰ˆæœ¬)

#### ğŸ”§ æŠ€æœ¯æ”¹è¿›
- **ç°ä»£åŒ–é…ç½® API**: ä½¿ç”¨æ–°çš„ `Configuration` + `ConfigOptions` æ¨¡å¼
- **å®‰å…¨æ€§å¢å¼º**: ç”¨ Jackson ObjectMapper æ›¿æ¢ FastJSON
- **ä¾èµ–ç®¡ç†ä¼˜åŒ–**: è§£å†³ç‰ˆæœ¬å†²çªï¼Œæ·»åŠ ç¼ºå¤±ä¾èµ–
- **Docker ä¼˜åŒ–**: ä¿®å¤ç½‘ç»œå†²çªï¼Œæ›´æ–°åŸºç¡€é•œåƒ
- **ä»£ç ç°ä»£åŒ–**: ç§»é™¤æ‰€æœ‰è¿‡æ—¶ API å’Œè­¦å‘Š

#### ğŸš€ æ€§èƒ½æå‡
- **Java 17 ä¼˜åŠ¿**: æ”¹è¿›çš„ GC æ€§èƒ½å’Œå†…å­˜æ•ˆç‡
- **Flink 1.20.1 ç‰¹æ€§**: æ›´å¥½çš„æ£€æŸ¥ç‚¹æœºåˆ¶å’ŒçŠ¶æ€ç®¡ç†
- **è¿æ¥å™¨æ›´æ–°**: æœ€æ–°çš„ Kafkaã€JDBC å’Œ CDC è¿æ¥å™¨ï¼Œç¨³å®šæ€§æ›´ä½³

> ğŸ“– **è¿ç§»æŒ‡å—**: è¯¦ç»†å‡çº§è¯´æ˜è¯·å‚è€ƒ [CHANGELOG.md](CHANGELOG.md)

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### æ–¹å¼ä¸€ï¼šè‡ªåŠ¨åŒ–éƒ¨ç½²ï¼ˆæ¨èï¼‰
```bash
# 1. ç¯å¢ƒå‡†å¤‡ï¼šè‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–
./scripts/setup.sh

# 2. å…‹éš†ä»“åº“
git clone https://github.com/yourusername/flink-demo.git
cd flink-demo

# 3. ä¼ä¸šçº§æ„å»ºï¼ˆåŒ…å«æµ‹è¯•ã€è´¨é‡æ£€æŸ¥ï¼‰
./scripts/build.sh

# 4. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# 5. éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps
```

#### æ–¹å¼äºŒï¼šæ‰‹åŠ¨éƒ¨ç½²
```bash
# 1. æ£€æŸ¥ä¾èµ–ç¯å¢ƒ
java -version  # éœ€è¦ Java 11+ï¼ˆæ¨èJava 17ç”¨äºå¼€å‘ï¼‰
mvn -version   # éœ€è¦ Maven 3.6+
docker --version
docker-compose --version

# 2. å…‹éš†ä»“åº“
git clone https://github.com/yourusername/flink-demo.git
cd flink-demo

# 3. Maven æ„å»º
mvn clean package -DskipTests

# 4. å¯åŠ¨æ‰€æœ‰æœåŠ¡ (ä¸€é”®éƒ¨ç½²)
docker-compose up --build -d

# 5. éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps
```

#### æ„å»ºé€‰é¡¹
```bash
# ğŸ”¥ å®Œæ•´æ„å»ºï¼ˆæµ‹è¯• + è´¨é‡æ£€æŸ¥ï¼‰
./scripts/build.sh

# âš¡ å¿«é€Ÿæ„å»ºï¼ˆè·³è¿‡æµ‹è¯•ï¼‰
./scripts/build.sh --quick

# ğŸ³ è·³è¿‡ Docker æ„å»º
./scripts/build.sh --skip-docker

# ğŸ“– æŸ¥çœ‹å¸®åŠ©
./scripts/build.sh --help
```

### ğŸŒ æœåŠ¡è®¿é—®

| æœåŠ¡ | åœ°å€ | é»˜è®¤å‡­æ® âš ï¸ |
|------|------|------|
| **Flink æ§åˆ¶å°** | http://localhost:8081 | - |
| **MySQL (Adminer)** | http://localhost:8080 | root/root123 |
| **Doris FE** | http://localhost:8030 | root/(ç©º) |
| **StreamPark** | http://localhost:10000 | admin/streampark |

> âš ï¸ **å®‰å…¨è­¦å‘Š**ï¼šä»¥ä¸Šæ˜¯æ¼”ç¤ºç”¨é»˜è®¤å‡­æ®ï¼Œ**ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ›´æ”¹**ï¼  
> ğŸ“‹ å‚è€ƒï¼š[å®‰å…¨é…ç½®æŒ‡å—](#-å®‰å…¨é…ç½®)

### ğŸ› ï¸ æœåŠ¡æ¦‚è§ˆ

| æœåŠ¡ | ç‰ˆæœ¬ | ç«¯å£ | æè¿° |
|------|------|------|------|
| **Apache Flink** | 1.20.1 | 8081 | æµå¤„ç†å¼•æ“ + Paimon è¿æ¥å™¨ |
| **Apache Kafka** | Latest | 9092 | åˆ†å¸ƒå¼æµå¤„ç†å¹³å° |
| **MySQL** | 8.0 | 3306 | å…³ç³»å‹æ•°æ®åº“ï¼Œå¯ç”¨ CDC |
| **Apache Doris** | Latest | 8030, 9030 | MPP åˆ†æå‹æ•°æ®åº“ |
| **Redis** | 6.2 | 6379 | å†…å­˜æ•°æ®ç»“æ„å­˜å‚¨ |
| **StreamPark** | 2.1.5 | 10000 | Flink ä½œä¸šç®¡ç†å¹³å° |

### ğŸ“– ä½¿ç”¨ç¤ºä¾‹

#### ğŸš€ å®Œæ•´ Paimon å¿«é€Ÿå…¥é—¨æ•™ç¨‹

æœ¬æ•™ç¨‹æä¾›äº†é€æ­¥æŒ‡å—æ¥æµ‹è¯• Paimon çš„å®æ—¶æ•°æ®åŠŸèƒ½ã€‚

**ç¬¬1æ­¥ï¼šè¿›å…¥ Flink SQL å®¢æˆ·ç«¯**
```bash
# è¿›å…¥ Flink JobManager å®¹å™¨
docker exec -it jobmanager bash

# å¯åŠ¨ Flink SQL å®¢æˆ·ç«¯
./bin/sql-client.sh
```

**ç¬¬2æ­¥ï¼šåŸºç¡€ Paimon è®¾ç½®ï¼ˆå¤åˆ¶å³å¯è¿è¡Œï¼‰**
```sql
-- åˆ›å»º Paimon ç›®å½•
CREATE CATALOG my_catalog WITH (
  'type' = 'paimon',
  'warehouse' = 'file:/warehouse'
);

-- åˆ‡æ¢åˆ° Paimon ç›®å½•ï¼ˆé‡è¦ï¼šåç»­æ“ä½œå¿…éœ€ï¼‰
USE CATALOG my_catalog;

-- åˆ›å»ºå¸¦ä¸»é”®çš„ä¸»è¡¨
-- æ³¨ï¼šPRIMARY KEY NOT ENFORCED è¡¨ç¤ºæ”¯æŒå»é‡ä½†ä¸å¼ºåˆ¶
CREATE TABLE word_count (
  word STRING PRIMARY KEY NOT ENFORCED,
  cnt BIGINT
);

-- åˆ›å»ºæ•°æ®æºè¡¨ï¼Œä½¿ç”¨ Flink å†…ç½®çš„ datagen æ•°æ®ç”Ÿæˆå™¨
CREATE TEMPORARY TABLE word_table (
  word STRING
) WITH (
  'connector' = 'datagen',
  'fields.word.length' = '1'  -- ç”Ÿæˆå•å­—ç¬¦å•è¯ (a, b, c, ç­‰)
);

-- å¯ç”¨æ£€æŸ¥ç‚¹ä»¥ä¿è¯å®¹é”™
SET 'execution.checkpointing.interval' = '10 s';

-- å¼€å§‹æµå¼ä½œä¸šï¼šæ’å…¥å®æ—¶èšåˆæ•°æ®
INSERT INTO word_count
SELECT word, COUNT(*) FROM word_table GROUP BY word;
```

**ç¬¬3æ­¥ï¼šå®æ—¶ç›‘æ§ç»“æœ**

åœ¨ INSERT ä½œä¸šè¿è¡Œæ—¶ï¼Œ**æ‰“å¼€ç¬¬äºŒä¸ªç»ˆç«¯ä¼šè¯**ï¼š
```bash
# æ‰“å¼€å¦ä¸€ä¸ª SQL å®¢æˆ·ç«¯ä¼šè¯
docker exec -it jobmanager ./bin/sql-client.sh
```

```sql
USE CATALOG my_catalog;

-- æŸ¥è¯¢å®æ—¶ç»“æœï¼ˆå°†æ˜¾ç¤ºæŒç»­å¢é•¿çš„è®¡æ•°ï¼‰
SELECT * FROM word_count;

-- é¢„æœŸè¾“å‡ºï¼ˆè®¡æ•°ä¼šæŒç»­å¢åŠ ï¼‰ï¼š
/*
+----+--------------------------------+----------------------+
| op |                           word |                  cnt |
+----+--------------------------------+----------------------+
| +I |                              a |                   45 |
| +I |                              b |                   38 |
| +I |                              c |                   42 |
| +I |                              d |                   51 |
+----+--------------------------------+----------------------+
*/
```

**ç¬¬4æ­¥ï¼šåˆ‡æ¢åˆ°æ‰¹å¤„ç†æ¨¡å¼ï¼ˆOLAP æŸ¥è¯¢ï¼‰**
```sql
-- é…ç½®æ‰¹å¤„ç†æ¨¡å¼ï¼ˆé™æ€å¿«ç…§ï¼‰
SET 'sql-client.execution.result-mode' = 'tableau';
RESET 'execution.checkpointing.interval';
SET 'execution.runtime-mode' = 'batch';

-- æŸ¥è¯¢é™æ€å¿«ç…§ï¼ˆä¸ä¼šè‡ªåŠ¨åˆ·æ–°ï¼‰
SELECT * FROM word_count ORDER BY cnt DESC LIMIT 5;

-- è¿™æ¼”ç¤ºäº† Paimon çš„"å­˜ç®—åˆ†ç¦»"è®¾è®¡
-- æµæ¨¡å¼ï¼šå®æ—¶æ›´æ–° | æ‰¹æ¨¡å¼ï¼šé™æ€åˆ†æ
```

**ç¬¬5æ­¥ï¼šé«˜çº§ç¤ºä¾‹ - ä¸šåŠ¡è¡¨**
```sql
-- åˆ›å»ºä¸šåŠ¡è®¢å•è¡¨
CREATE TABLE orders (
  order_id BIGINT,
  user_id BIGINT,
  product_id BIGINT,
  order_time TIMESTAMP(3),
  amount DECIMAL(10,2),
  PRIMARY KEY (order_id) NOT ENFORCED
) WITH ('bucket' = '4');

-- æ’å…¥ç¤ºä¾‹æ•°æ®
INSERT INTO orders VALUES
(1001, 101, 201, TIMESTAMP '2024-01-15 10:30:00', 99.99),
(1002, 102, 202, TIMESTAMP '2024-01-15 11:15:00', 149.50),
(1003, 101, 203, TIMESTAMP '2024-01-15 12:00:00', 79.99);

-- æŸ¥è¯¢æ•°æ®
SELECT * FROM orders;
```

**ç¬¬6æ­¥ï¼šæ¸…ç†ä¸é€€å‡º**
```sql
-- å¯é€‰æ¸…ç†
DROP TABLE word_count;
DROP TABLE orders;

-- é€€å‡º SQL å®¢æˆ·ç«¯
QUIT;
```

#### ğŸ“Š é¢„æœŸç»“æœä¸éªŒè¯

1. **Flink Web UI çŠ¶æ€**ï¼šè®¿é—® http://localhost:8081 æŸ¥çœ‹è¿è¡Œä¸­çš„ä½œä¸š
2. **å®æ—¶å¢é•¿**ï¼š`word_count` æŸ¥è¯¢ç»“æœåº”æ˜¾ç¤ºé€’å¢çš„æ•°å­—
3. **æ‰¹æµåŒºåˆ«**ï¼šæ³¨æ„ä¸åŒæ¨¡å¼ä¸‹æŸ¥è¯¢è¡Œä¸ºçš„å·®å¼‚

#### ğŸ” æ•…éšœæ’æŸ¥æç¤º

- **ç›®å½•é”™è¯¯**ï¼šåˆ›å»ºç›®å½•ååŠ¡å¿…ä½¿ç”¨ `USE CATALOG my_catalog`
- **æ— æ•°æ®**ï¼šæ£€æŸ¥ INSERT ä½œä¸šæ˜¯å¦åœ¨ Flink Web UI ä¸­è¿è¡Œ
- **æƒé™é—®é¢˜**ï¼šç¡®ä¿å®¹å™¨ä¸­ `/warehouse` ç›®å½•å¯å†™

#### ğŸ“„ ç°æˆçš„æµ‹è¯•è„šæœ¬

ä¸ºæ–¹ä¾¿ä½¿ç”¨ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å®Œæ•´çš„æµ‹è¯•è„šæœ¬ï¼š
```bash
# æŸ¥çœ‹ç°æˆçš„ SQL è„šæœ¬
cat examples/paimon-quick-test.sql

# æˆ–åœ¨ SQL å®¢æˆ·ç«¯ä¸­ç›´æ¥æ‰§è¡Œ
```
è¯¥è„šæœ¬åŒ…å«ä¸Šè¿°æ‰€æœ‰å‘½ä»¤ï¼Œå¹¶æä¾›ä¸­è‹±æ–‡è¯¦ç»†æ³¨é‡Šã€‚

#### ğŸ”„ MySQL CDC åˆ° Paimon ç¤ºä¾‹
```sql
-- åˆ›å»º MySQL CDC æºè¡¨
CREATE TABLE mysql_orders (
  order_id BIGINT,
  user_id BIGINT,
  product_id BIGINT,
  order_time TIMESTAMP(3),
  amount DECIMAL(10,2),
  PRIMARY KEY (order_id) NOT ENFORCED
) WITH (
  'connector' = 'mysql-cdc',
  'hostname' = 'mysql',
  'port' = '3306',
  'username' = 'root',
  'password' = 'root123',
  'database-name' = 'ods',
  'table-name' = 'orders'
);

-- æ’å…¥åˆ° Paimon è¡¨
INSERT INTO my_catalog.default.orders
SELECT * FROM mysql_orders;
```

### ğŸ”§ å¼€å‘æŒ‡å—

#### æ·»åŠ è‡ªå®šä¹‰ JAR
1. å°† JAR æ–‡ä»¶æ”¾å…¥ `flink-jars/` ç›®å½•
2. é‡æ–°æ„å»ºï¼š`docker-compose up --build -d jobmanager taskmanager`

#### è‡ªå®šä¹‰é…ç½®
- **Flink é…ç½®**ï¼šç¼–è¾‘ `docker-compose.yml` ä¸­çš„ `FLINK_PROPERTIES`
- **MySQL åˆå§‹åŒ–**ï¼šå°†è„šæœ¬æ”¾å…¥ `sql-scripts/` ç›®å½•
- **Doris é…ç½®**ï¼šä¿®æ”¹ `doris/*/conf/` ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶

#### é¡¹ç›®ç»“æ„
```
flink-demo/
â”œâ”€â”€ docker-compose.yml          # ä¸»è¦ç¼–æ’æ–‡ä»¶
â”œâ”€â”€ flink/
â”‚   â””â”€â”€ Dockerfile             # è‡ªå®šä¹‰ Flink é•œåƒ
â”œâ”€â”€ flink-jars/                # è‡ªå®šä¹‰ JAR æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ paimon-flink-*.jar    # Paimon è¿æ¥å™¨
â”œâ”€â”€ doris/                     # Doris é…ç½®
â”œâ”€â”€ sql-scripts/               # MySQL åˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ .dockerignore              # Docker æ„å»ºå¿½ç•¥è§„åˆ™
â”œâ”€â”€ README.md                  # æœ¬æ–‡ä»¶
â””â”€â”€ DEPLOYMENT.md              # è¯¦ç»†éƒ¨ç½²æŒ‡å—
```

### ğŸ” æ•…éšœæ’æŸ¥

#### å¸¸è§é—®é¢˜

1. **æœåŠ¡æ— æ³•å¯åŠ¨**
   ```bash
   # æŸ¥çœ‹æ—¥å¿—
   docker-compose logs [æœåŠ¡å]
   
   # é‡å¯ç‰¹å®šæœåŠ¡
   docker-compose restart [æœåŠ¡å]
   ```

2. **ç«¯å£å†²çª**
   ```bash
   # æ£€æŸ¥ç«¯å£å ç”¨
   netstat -tlnp | grep :8081
   
   # å¦‚éœ€è¦å¯ä¿®æ”¹ docker-compose.yml ä¸­çš„ç«¯å£
   ```

3. **èµ„æºä¸è¶³**
   ```bash
   # æ£€æŸ¥ Docker èµ„æº
   docker system df
   docker system prune  # æ¸…ç†æœªä½¿ç”¨çš„èµ„æº
   ```

4. **Paimon JAR æœªæ‰¾åˆ°**
   ```bash
   # éªŒè¯ JAR æ–‡ä»¶æ˜¯å¦å­˜åœ¨äºå®¹å™¨ä¸­
   docker exec jobmanager find /opt/flink/lib -name "*paimon*"
   
   # å¦‚æœ‰å¿…è¦é‡æ–°æ„å»º
   docker-compose build --no-cache jobmanager taskmanager
   ```

### ğŸ›¡ï¸ å®‰å…¨é…ç½®

âš ï¸ **é‡è¦**ï¼šæœ¬é¡¹ç›®é»˜è®¤é…ç½®ä»…ç”¨äºå¼€å‘å’Œæ¼”ç¤ºï¼Œ**ç”Ÿäº§ç¯å¢ƒå¿…é¡»è¿›è¡Œå®‰å…¨åŠ å›º**ï¼

#### å¿«é€Ÿå®‰å…¨é…ç½®
1. **å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿**ï¼š
   ```bash
   cp env.template .env
   ```

2. **ä¿®æ”¹ `.env` æ–‡ä»¶ä¸­çš„æ•æ„Ÿä¿¡æ¯**ï¼š
   ```bash
   # æ•°æ®åº“å¯†ç ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰
   MYSQL_ROOT_PASSWORD=YourSecurePassword123!
   MYSQL_PASSWORD=YourAppPassword123!
   
   # Redis å¯†ç 
   REDIS_PASSWORD=YourRedisPassword123!
   ```

3. **æ›´æ–° docker-compose.yml ä½¿ç”¨ç¯å¢ƒå˜é‡**ï¼š
   ```yaml
   environment:
     - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
     - MYSQL_PASSWORD=${MYSQL_PASSWORD}
   ```

#### ç”Ÿäº§å®‰å…¨æ£€æŸ¥æ¸…å•

- [ ] ğŸ” **æ›´æ”¹æ‰€æœ‰é»˜è®¤å¯†ç **
- [ ] ğŸš« **ç¦ç”¨ä¸å¿…è¦çš„ç«¯å£æš´éœ²**
- [ ] ğŸ”’ **å¯ç”¨ SSL/TLS åŠ å¯†**
- [ ] ğŸ‘¤ **é…ç½®è®¿é—®æ§åˆ¶å’Œç”¨æˆ·æƒé™**
- [ ] ğŸ“ **å¯ç”¨å®¡è®¡æ—¥å¿—**
- [ ] ğŸ  **é…ç½®ç½‘ç»œéš”ç¦»**
- [ ] ğŸ›¡ï¸ **å®šæœŸå®‰å…¨æ‰«æå’Œæ›´æ–°**

#### ç½‘ç»œå®‰å…¨
```yaml
# ä»…å†…éƒ¨ç½‘ç»œé€šä¿¡ï¼Œä¸æš´éœ²æ•æ„Ÿç«¯å£
services:
  mysql:
    ports: []  # ç§»é™¤ç«¯å£æš´éœ²
  redis:
    ports: []  # ç§»é™¤ç«¯å£æš´éœ²
```

### ğŸ”§ æ€§èƒ½è°ƒä¼˜

ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼š

1. **å¢åŠ å†…å­˜åˆ†é…**ï¼š
   ```yaml
   environment:
     - "FLINK_PROPERTIES=taskmanager.memory.process.size: 2gb"
   ```

2. **è°ƒæ•´å¹¶è¡Œåº¦**ï¼š
   ```yaml
   environment:
     - "FLINK_PROPERTIES=parallelism.default: 4"
   ```

3. **é…ç½®æ£€æŸ¥ç‚¹**ï¼š
   ```yaml
   environment:
     - "FLINK_PROPERTIES=execution.checkpointing.interval: 30s"
   ```

4. **è´¨é‡é—¨ç¦**ï¼š
   ```bash
   # è¿è¡Œå®Œæ•´è´¨é‡æ£€æŸ¥
   mvn clean package -P quality-check
   
   # ä»£ç è¦†ç›–ç‡æŠ¥å‘Š
   open target/site/jacoco/index.html
   ```

### ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚

#### å¼€å‘æµç¨‹
1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

### ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚

### ğŸ™ è‡´è°¢

- [Apache Flink](https://flink.apache.org/) - æµå¤„ç†æ¡†æ¶
- [Apache Paimon](https://paimon.apache.org/) - æ¹–ä»“å­˜å‚¨ç³»ç»Ÿ
- [Apache Kafka](https://kafka.apache.org/) - åˆ†å¸ƒå¼æµå¤„ç†å¹³å°
- [Apache Doris](https://doris.apache.org/) - MPP åˆ†æå‹æ•°æ®åº“
- [Docker](https://www.docker.com/) - å®¹å™¨åŒ–å¹³å°

### ğŸ“ æ”¯æŒ

- ğŸ“ [é¡¹ç›®ç»“æ„](./PROJECT_STRUCTURE.md)
- ğŸ“š [éƒ¨ç½²æ–‡æ¡£](./DEPLOYMENT.md)
- ğŸ§ª [æµ‹è¯•æŒ‡å—](./TESTING_GUIDE.md)
- ğŸ“– [Flink SQL æŒ‡å—](./FLINK_SQL_COMMANDS_GUIDE.md)
- ğŸ”§ [è´¡çŒ®æŒ‡å—](./CONTRIBUTING.md)
- ğŸ› [é—®é¢˜åé¦ˆ](https://github.com/yourusername/flink-demo/issues)
- ğŸ’¬ [è®¨è®ºåŒº](https://github.com/yourusername/flink-demo/discussions)

---

â­ **å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªæ˜Ÿæ ‡ï¼ | Star this repository if it helped you!**

## ğŸ”„ Flink 1.20.1 å‡çº§æŒ‡å—

### é‡å¤§å˜æ›´è¯´æ˜

æœ¬é¡¹ç›®å·²ä» **Apache Flink 1.17.1** å‡çº§è‡³ **Apache Flink 1.20.1**ï¼ŒåŒæ—¶å°† **Java è¿è¡Œæ—¶ä» 11 å‡çº§åˆ° 17**ã€‚

### å‡çº§å†…å®¹

#### ğŸš€ æ ¸å¿ƒç»„ä»¶å‡çº§
- **Apache Flink**: 1.17.1 â†’ 1.20.1
- **Java è¿è¡Œæ—¶**: 11 â†’ 17  
- **Apache Paimon**: 0.8.2 â†’ 1.0.0 (å®é™…ä½¿ç”¨ç‰ˆæœ¬)
- **è¿æ¥å™¨ç‰ˆæœ¬**: æ›´æ–°è‡³æœ€æ–°å…¼å®¹ç‰ˆæœ¬

#### ğŸ†• æ–°åŠŸèƒ½æ”¯æŒ
- **Materialized Tables**: ç®€åŒ–æ•°æ®ç®¡é“å¼€å‘
- **ç»Ÿä¸€æ–‡ä»¶åˆå¹¶æ£€æŸ¥ç‚¹**: å‡å°‘å°æ–‡ä»¶æ•°é‡
- **å¢å¼ºçš„æ‰¹å¤„ç†ä½œä¸šæ¢å¤**: JobMaster æ•…éšœåæ¢å¤
- **æ–°çš„ Sink API**: SinkFunction å·²å¼ƒç”¨

#### ğŸ›¡ï¸ å®‰å…¨æ”¹è¿›
- ç§»é™¤ FastJSONï¼Œä½¿ç”¨å®‰å…¨çš„ Jackson åº“
- æ›´æ–°æ‰€æœ‰ä¾èµ–è‡³æœ€æ–°å®‰å…¨ç‰ˆæœ¬

### è¿ç§»æ­¥éª¤

#### 1. ç¯å¢ƒå‡†å¤‡
ç¡®ä¿å¼€å‘ç¯å¢ƒå®‰è£… Java 17+ï¼š

```bash
# æ£€æŸ¥ Java ç‰ˆæœ¬
java -version

# å¦‚æœä½¿ç”¨ SDKMAN
sdk install java 17.0.8-tem
sdk use java 17.0.8-tem
```

#### 2. é‡æ–°æ„å»ºé¡¹ç›®
```bash
# æ¸…ç†æ—§æ„å»º
mvn clean

# é‡æ–°æ„å»º
mvn compile package

# æ„å»º Docker é•œåƒ
docker build -t custom-flink:1.20.1-paimon -f flink/Dockerfile .
```

#### 3. æ›´æ–° Docker Compose
å·²è‡ªåŠ¨æ›´æ–°é•œåƒæ ‡ç­¾ä¸º `custom-flink:1.20.1-paimon`ï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹ã€‚

#### 4. éªŒè¯å‡çº§
```bash
# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æ£€æŸ¥ Flink ç‰ˆæœ¬
curl http://localhost:8081/config

# éªŒè¯ Paimon è¿æ¥å™¨
docker exec jobmanager find /opt/flink/lib -name "*paimon*"
```

### å…¼å®¹æ€§è¯´æ˜

#### âœ… ä¿æŒå…¼å®¹
- ç°æœ‰çš„ DataStream API ä»£ç 
- Kafka/MySQL è¿æ¥é…ç½®
- æ£€æŸ¥ç‚¹å’ŒçŠ¶æ€åç«¯é…ç½®
- ç°æœ‰çš„ SQL æŸ¥è¯¢å’Œè¡¨å®šä¹‰

#### âš ï¸ éœ€è¦æ³¨æ„
- **JSON å¤„ç†**: FastJSON å·²æ›¿æ¢ä¸º Jackson
- **è¿æ¥å™¨ç‰ˆæœ¬**: æŸäº›è¿æ¥å™¨å¯èƒ½éœ€è¦é‡æ–°æµ‹è¯•
- **æ–°æ£€æŸ¥ç‚¹åŠŸèƒ½**: å¯é€‰å¯ç”¨æ–‡ä»¶åˆå¹¶åŠŸèƒ½

### æ–°åŠŸèƒ½ä½¿ç”¨

#### Materialized Tables (å®éªŒæ€§)
```sql
-- åˆ›å»ºç‰©åŒ–è¡¨
CREATE MATERIALIZED TABLE orders_summary
PARTITIONED BY (ds)
FRESHNESS = INTERVAL '1' HOUR
AS SELECT 
  ds,
  COUNT(*) as order_count,
  SUM(amount) as total_amount
FROM orders 
GROUP BY ds;
```

#### å¯ç”¨æ–‡ä»¶åˆå¹¶æ£€æŸ¥ç‚¹
```yaml
# flink-conf.yaml
execution.checkpointing.file-merging.enabled: true
```

### æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜
1. **ä¾èµ–å†²çª**: æ¸…ç† Maven ç¼“å­˜ `mvn dependency:purge-local-repository`
2. **è¿æ¥å™¨é—®é¢˜**: æ£€æŸ¥è¿æ¥å™¨ç‰ˆæœ¬å…¼å®¹æ€§
3. **çŠ¶æ€æ¢å¤**: éªŒè¯æ£€æŸ¥ç‚¹å­˜å‚¨è·¯å¾„

#### è·å¾—å¸®åŠ©
- æŸ¥çœ‹ [Flink 1.20 å‡çº§æŒ‡å—](https://flink.apache.org/docs/stable/ops/upgrading/)
- æäº¤ Issue åˆ°é¡¹ç›®ä»“åº“
- å‚è€ƒå®˜æ–¹è¿ç§»æ–‡æ¡£

--- 