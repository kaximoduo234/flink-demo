services:
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - flink-network

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_NUM_PARTITIONS=2
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_HEAP_OPTS=-Xms256m -Xmx256m
      - KAFKA_CFG_LOG_RETENTION_HOURS=6
      - KAFKA_CFG_LOG_RETENTION_BYTES=268435456
    volumes:
      - ./kafka-data:/bitnami/kafka
    depends_on:
      - zookeeper
    networks:
      - flink-network

  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=root123
      - MYSQL_DATABASE=ods
      - MYSQL_USER=testuser
      - MYSQL_PASSWORD=testpass
      - TZ=Asia/Shanghai
    command: [
      "--character-set-server=utf8mb4",
      "--collation-server=utf8mb4_unicode_ci",
      "--log-bin=mysql-bin",
      "--binlog-format=ROW",
      "--binlog-row-image=FULL",
      "--server-id=1"
    ]
    volumes:
      - ./mysql-data:/var/lib/mysql
      - ./sql-scripts:/docker-entrypoint-initdb.d
    networks:
      - flink-network

  # zeppelin 容器已移除 - 使用 Docker 容器中的 Flink SQL Gateway 替代

  jobmanager:
    build:
      context: .
      dockerfile: flink/Dockerfile
      args:
        - PAIMON_VERSION=1.0.0
        - FLINK_VERSION=1.20.1
      target: runtime  # 指定构建目标阶段
    image: custom-flink:1.20.1-paimon-optimized
    container_name: jobmanager
    ports:
      - "8081:8081"  # Flink Web UI
      - "6123:6123"  # Flink RPC 端口 (用于调试和远程连接)
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 8
        parallelism.default: 1
        # 内存优化配置
        jobmanager.memory.process.size: 2g
        jobmanager.memory.flink.size: 1600m
        # 检查点配置
        execution.checkpointing.interval: 60s
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
      - FLINK_ENV_JAVA_OPTS=-XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UseStringDeduplication -XX:+OptimizeStringConcat
    volumes:
      - ./target:/opt/flink/usrlib:ro
      - ./checkpoints:/opt/flink/checkpoints
      - ./paimon-warehouse:/warehouse
      - ./flink-jars:/opt/flink/lib/connectors:ro  # 🔥 只读挂载连接器
    networks:
      - flink-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 15s  # 🔥 更频繁检查
      timeout: 5s    # 🔥 更快超时
      retries: 3
      start_period: 30s  # 🔥 减少等待时间

  taskmanager:
    build:
      context: .
      dockerfile: flink/Dockerfile
      args:
        - PAIMON_VERSION=1.0.0
        - FLINK_VERSION=1.20.1
      target: runtime
    image: custom-flink:1.20.1-paimon-optimized
    container_name: taskmanager
    ports:
      - "6124:6124"  # TaskManager RPC 端口 (可选，用于调试)
    depends_on:
      jobmanager:
        condition: service_healthy  # 等待 JobManager 健康后启动
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 8
        parallelism.default: 1
        # TaskManager 内存优化
        taskmanager.memory.process.size: 4g
        taskmanager.memory.flink.size: 3200m
        taskmanager.memory.managed.fraction: 0.4
      - FLINK_ENV_JAVA_OPTS=-XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UseStringDeduplication -XX:+OptimizeStringConcat
    volumes:
      - ./target:/opt/flink/usrlib:ro
      - ./checkpoints:/opt/flink/checkpoints
      - ./paimon-warehouse:/warehouse
      - ./flink-jars:/opt/flink/lib/connectors:ro  # 🔥 只读挂载连接器
    networks:
      - flink-network
    restart: unless-stopped

  streampark:
    image: apache/streampark:2.1.5
    container_name: streampark
    restart: always
    ports:
      - "10000:10000"  # Web UI 默认端口
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - FLINK_REST_URL=http://jobmanager:8081
    depends_on:
      jobmanager:
        condition: service_started  # 🔥 只需要服务启动，不需要健康检查
      taskmanager:
        condition: service_started
      # 移除 StarRocks 强依赖，StreamPark 主要管理 Flink 作业
    networks:
      - flink-network

  redis:
    image: redis:6.2
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - flink-network

  starrocks:
    image: starrocks/allin1-ubuntu:3.5.0
    container_name: starrocks
    restart: on-failure
    ports:
      - "8030:8030"   # FE HTTP UI
      - "9030:9030"   # FE MySQL 接口
      - "8040:8040"   # BE Web UI
    networks:
      - flink-network
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./starrocks-storage:/opt/starrocks-storage
    healthcheck:
      test: ["CMD", "mysql", "-h127.0.0.1", "-P9030", "-uroot", "-e", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Flink SQL Gateway (修正 YAML 配置格式)
  sql-gateway:
    build:
      context: .
      dockerfile: flink/Dockerfile
      args:
        - PAIMON_VERSION=1.0.0
        - FLINK_VERSION=1.20.1
      target: runtime
    image: custom-flink:1.20.1-paimon-optimized
    container_name: sql-gateway
    depends_on:
      jobmanager:
        condition: service_healthy  # 必须等待JobManager健康
      taskmanager:
        condition: service_started  # TaskManager只需启动即可
    command: ["bin/sql-gateway.sh", "start-foreground"]
    ports:
      - "8083:8083"
    networks:
      - flink-network
    volumes:
      - ./target:/opt/flink/usrlib:ro
      - ./checkpoints:/opt/flink/checkpoints
      - ./paimon-warehouse:/warehouse
      - ./flink-jars:/opt/flink/lib/connectors:ro  # 🔥 只读挂载连接器
      - ./scripts:/opt/scripts:ro  # 🔥 挂载初始化脚本
    environment:
      - |
        FLINK_PROPERTIES=
        sql-gateway.endpoint.rest.address: 0.0.0.0
        sql-gateway.endpoint.rest.port: 8083
        execution.target: remote
        jobmanager.rpc.address: jobmanager
        jobmanager.rpc.port: 6123
        rest.address: jobmanager
        rest.port: 8081
        execution.runtime-mode: streaming
        parallelism.default: 1
        table.exec.sink.upsert-materialize: NONE
      - FLINK_ENV_JAVA_OPTS=-XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UseStringDeduplication -XX:+OptimizeStringConcat
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/v1/info"]
      interval: 10s  # 🔥 更频繁检查
      timeout: 5s    # 🔥 更快超时
      retries: 3
      start_period: 20s  # 🔥 减少等待时间

  # 🔥 Catalog 自动初始化服务
  catalog-init:
    build:
      context: .
      dockerfile: flink/Dockerfile
      args:
        - PAIMON_VERSION=1.0.0
        - FLINK_VERSION=1.20.1
      target: runtime
    image: custom-flink:1.20.1-paimon-optimized
    container_name: catalog-init
    depends_on:
      sql-gateway:
        condition: service_healthy  # 等待 SQL Gateway 启动完成
    command: ["/opt/scripts/init_catalogs.sh"]
    volumes:
      - ./scripts:/opt/scripts:ro
      - ./paimon-warehouse:/warehouse
    networks:
      - flink-network
    restart: "no"  # 只运行一次，完成后退出

networks:
  flink-network:
    driver: bridge

volumes:
  kafka-data:
  mysql-data:
  paimon-warehouse:
  starrocks-storage: